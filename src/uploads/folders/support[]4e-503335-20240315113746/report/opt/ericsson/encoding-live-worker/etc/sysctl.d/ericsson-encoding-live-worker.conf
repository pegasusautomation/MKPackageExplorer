# Controls source route verification
# all values
net.ipv4.conf.all.arp_filter=0
net.ipv4.conf.all.rp_filter = 0
net.ipv4.conf.all.arp_ignore = 1
net.ipv4.conf.all.arp_announce = 2
net.ipv4.conf.all.force_igmp_version = 2
# default values
net.ipv4.conf.default.arp_filter=0
net.ipv4.conf.default.rp_filter = 0
net.ipv4.conf.default.arp_ignore = 1
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.default.force_igmp_version = 2
# disable ipv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1

#Network Performance
net.core.busy_read=50
net.core.busy_poll=50

# Increase Linux autotuning TCP buffer limits
#/proc/sys/net/core/rmem_max - Maximum TCP Receive Window
#/proc/sys/net/core/wmem_max - Maximum TCP Send Window
#/proc/sys/net/ipv4/tcp_rmem - memory reserved for TCP rcv buffers (reserved memory per connection default)
#/proc/sys/net/ipv4/tcp_wmem  - memory reserved for TCP snd buffers (reserved memory per connection default)
#/proc/sys/net/ipv4/tcp_timestamps - Timestamps (RFC 1323) add 12 bytes to the TCP header...
#/proc/sys/net/ipv4/tcp_sack - TCP Selective Acknowledgements. They can reduce retransmissions, however make servers more prone to DDoS Attacks and increase CPU utilization.
#/proc/sys/net/ipv4/tcp_window_scaling - support for large TCP Windows (RFC 1323). Needs to be set to 1 if the Max TCP Window is over 65535.
# Default Socket Receive Buffer
net.core.rmem_default = 268435456

# Maximum Socket Receive Buffer  (Performance tuning: Intel 10-gigabit NIC)
#BDP = (.1s) * (10 * 10^9 bit/s) = 10^9 bit = 1 Gbit ~= 2^30 bit = 134217728 B
net.core.rmem_max = 2147483647 

# Default Socket Send Buffer
net.core.wmem_default = 268435456

# Maximum Socket Send Buffer
net.core.wmem_max = 2147483647

# Increase number of incoming connections
net.core.somaxconn = 65535

# Increase number of incoming connections backlog (Performance tuning: Intel 10-gigabit NIC)
net.core.netdev_max_backlog = 300000

# Increase system IP port range to allow for more concurrent connections (Performance tuning: Intel 10-gigabit NIC)
net.ipv4.ip_local_port_range = 30000 65535

# Increase the maximum amount of option memory buffers
net.core.optmem_max = 268435456

# Increase the maximum total buffer-space allocatable
# This is measured in units of pages (4096 bytes)
net.ipv4.tcp_mem = 4096   87380   2147483647
net.ipv4.udp_mem = 4096   87380   2147483647

# Increase the read-buffer space allocatable
net.ipv4.tcp_rmem = 4096   87380   2147483647
net.ipv4.udp_rmem_min = 16384

# Increase the write-buffer-space allocatable
net.ipv4.tcp_wmem = 4096   87380   2147483647
net.ipv4.udp_wmem_min = 16384

# Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks
net.ipv4.tcp_max_tw_buckets = 2000000
#net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_tw_reuse = 1

# Make room for more TIME_WAIT sockets due to more clients,
# and allow them to be reused if we run out of sockets
# Also increase the max packet backlog
net.ipv4.tcp_max_syn_backlog = 300000
net.ipv4.tcp_fin_timeout = 15

# Disable TCP slow start on idle connections
net.ipv4.tcp_slow_start_after_idle = 0

net.ipv4.tcp_window_scaling = 1
# Disable the TCP timestamps option for better CPU utilization
net.ipv4.tcp_timestamps = 0
#Enable the TCP selective acks option for better throughput
net.ipv4.tcp_sack=1
net.ipv4.tcp_no_metrics_save = 1
# Enable low latency mode for TCP
net.ipv4.tcp_low_latency = 1

#awilk00: use bbr instead - requires "modprobe tcp_bbr" - ref https://djangocas.dev/blog/huge-improve-network-performance-by-change-tcp-congestion-control-to-bbr/
#net.ipv4.tcp_congestion_control = htcp
#net.ipv4.tcp_congestion_control = bbr

# recommended for hosts with jumbo frames enabled
net.ipv4.tcp_mtu_probing = 1

#for redis publication, Background save may fail under low memory condition
vm.overcommit_memory = 1
vm.overcommit_ratio = 95

#Decrease how long a migrated process has to be running before the kernel will consider migrating it again to another core
kernel.sched_migration_cost_ns=1

#Increase How many tasks can be moved by the softirqs
kernel.sched_nr_migrate=4096

#Increasing the amount of inotify watchers
fs.inotify.max_user_watches=65536

#recommended for CentOS7/Debian8 hosts
net.core.default_qdisc=fq

#One potential cause of poor performance on a Linux system is the amount of buffer space the RHEL 4u4 kernel uses to reassemble IP fragments
net.ipv4.ipfrag_high_thresh = 8388608

#increase semaphore value
#kernel.sem="250 256000 100 2048"
